# 线程

## 如何创建线程

使用threading模块中的Thread类来创建线程
```python
from threading import Thread

def task(n):
    for i in range(n):
        print(i)

thread1 = Thread(target=task, name='th1', args=(5, ))
thread2 = Thread(target=task, name='th2', args=(3, ))

thread1.start()
thread2.start()

thread1.join()
thread2.join()
```

重写Thread类的run方法创建线程
```python
import time
from threading import Thread

class MyThread(Thread):
    def __init__(self, name: str, count: int):
        super(MyThread, self).__init__()

        self.setName(name)  # 设置线程名
        self.count = count

    def run(self) -> None:
        for i in range(self.count):
            print(f"{self.getName()} - {i}")
            time.sleep(0.1)

th1 = MyThread('tha', 5)
th2 = MyThread('thb', 5)

th1.start()
th2.start()
```

## 守护线程
守护线程是特殊线程，当主线程结束，守护线程会自动结束。因此守护线程常常用于非关键性线程，比如日志

上面的`tha`和`thb`两个线程都是非守护线程，当所有非守护线程结束后，主线程才能结束。因此上述程序不用join来阻塞也是可以的

```python
def __init__(self, name: str, count: int):
    self.setDaemon(True)  # 在MyThread类的init函数中设置守护线程
```

在创建线程和调用时，只`start`不做`join`
程序执行
```commandline
C:\Users\user\Anaconda3\python.exe 
th1 - 0
th2 - 0
```


## 线程安全队列
queue模块中的Queue类提供了线程安全队列
- queue.put(item, block=False, timeout=3)
- queue.get(block=False, timeout=10)
- queue.qsize()
- queue.empty()
- queue.full()

---

- put中的block为True且timeout为None时，如果队列满了，就阻塞，直到队列有空间才put进去
- put的block为True且timeout为非负数时，如果队列满了，最多阻塞`timeout`秒，如果队列还满着，则抛异常
- put的block为False，如果队列有空余，则添加，否则直接抛异常且忽略`timeout`

---
- get中的block为True且timeout为None时，如果队列为空，则阻塞，直到队列有元素才弹出
- get中的block为True且timeout为非负数时，如果队列为空，最多阻塞`timeout`秒，如果队列还为空，则抛异常
- get中的block为False时，如果队列有元素，则直接弹出，否则直接抛异常且忽略`timeout`

## 生产者与消费者实例
```python
from queue import Queue
from threading import Thread

class MsgProducer(Thread):
    def __init__(self, name: str, count: int, queue: Queue):
        super(MsgProducer, self).__init__()

        self.setName(name)
        self.count = count  # 一共产生count条消息
        self.queue = queue

        # 这里不需要把生产者设为守护线程，
        # 因为线程产生完count条消息之后，线程就结束了

    def run(self) -> None:
        for i in range(self.count):
            msg = f"{self.getName()} - {i}"
            self.queue.put(msg, block=True)

class MsgConsumer(Thread):
    def __init__(self, name: str, queue: Queue):
        super(MsgConsumer, self).__init__()

        self.setName(name)
        self.queue = queue
        # 消费者设为守护进程，如果所有线程都结束了，
        # 消费者继续等着没有意义，直接和主线程一起结束
        self.setDaemon(True)

    def run(self) -> None:
        while True:
            msg = self.queue.get(block=True)
            print(f"{self.getName()} - {msg}\n", end='')

# 最多3个元素的队列
queue = Queue(3)
# 一共创建3个生产者，每个生产者创建10条消息
producer_threads = [MsgProducer(f"P{i}", 10, queue) for i in range(3)]  
# 一共创建2个消费者
customer_threads = [MsgConsumer(f"C{i}", queue) for i in range(2)]
threads = producer_threads + customer_threads

for t in threads:
    t.start()
```

## 线程锁
当多个线程在同一时刻访问相同数据时，可能出现数据丢失、覆盖、不完整等问题。

锁解决这一问题的方法，常用`threading.Lock` `threading.Condition`

举例，现有三个线程，每个线程都执行task任务。task任务中，共执行5轮，每轮分为3步。我们期望每个线程的3个步是一起完成的，不希望中间切换到其他线程。
```python
from threading import Thread

def task(name: str):
    for i in range(5):
        print(f"{name} - round {i} - step 1\n", end='')
        print(f"{name} - round {i} - step 2\n", end='')
        print(f"{name} - round {i} - step 3\n", end='')

th1 = Thread(target=task, args=('A',))
th2 = Thread(target=task, args=('B',))
th3 = Thread(target=task, args=('C',))

th1.start()
th2.start()
th3.start()
```

执行结果:
```
...
A - round 2 - step 1
A - round 2 - step 2
A - round 2 - step 3
A - round 3 - step 1
B - round 0 - step 1  A的第三轮 中间切换成了B
A - round 3 - step 2
A - round 3 - step 3
...
```

改进方案，通过锁，将task中的3步操作 原子化
```python
from threading import Thread, Lock

task_lock = Lock()

def task(name: str):
    for i in range(2):
        
        task_lock.acquire()  # 加锁
        print(f"{name} - round {i} - step 1\n", end='')
        print(f"{name} - round {i} - step 2\n", end='')
        print(f"{name} - round {i} - step 3\n", end='')
        task_lock.release()  # 释放锁
```

实现Queue
```python
from threading import Condition

class SafeQueue:
    def __init__(self, size: int):
        self.__item_list = list()
        self.size = size
        self.__lock = Condition()

    def put(self, item):
        self.__lock.acquire()
        while len(self.__item_list) >= self.size:
            self.__lock.wait()  # 队列满了，等待get方法的pop唤醒

        self.__item_list.append(item)
        self.__lock.notify_all()
        self.__lock.release()

    def get(self):
        # 通过上下文管理器，简化aquire和release代码
        with self.__lock:
            while len(self.__item_list) == 0:
                self.__lock.wait()
    
            result = self.__item_list.pop(0)
            # 此处唤醒所有等待锁的线程，当然，也包括get方法的wait
            # 如果只唤醒其中某几个线程，可能会唤醒等待get的线程，这也做无意义
            # 因此所有等待线程全都唤醒
            self.__lock.notify_all()
    
        return result
```

## 线程池
- 线程的创建和销毁比较昂贵
- 频繁的创建和销毁线程不利于高性能

注：阻塞一般写在被线程调用的函数或方法中，线程池本身只是负责调度线程

线程池实例

方法一: submit
```python
import time
from concurrent.futures import ThreadPoolExecutor

def task(name: str):
    print(f"{name} - step 1\n", end='')
    time.sleep(1)
    print(f"{name} - step 2\n", end='')
    return f"{name} finish"

with ThreadPoolExecutor() as executor:
    # 启动两个线程
    result1 = executor.submit(task, 'A')
    result2 = executor.submit(task, 'B')
    # 等待结果
    print(result1.result())
    print(result2.result())
```
如果有多种task时，可以用一个线程池来调度，每个task都去submit

方法二: map
```python
import time
from concurrent.futures import ThreadPoolExecutor

def task(name: str):
    print(f"{name} - step 1\n", end='')
    time.sleep(1)
    print(f"{name} - step 2\n", end='')
    return f"{name} finish"

with ThreadPoolExecutor() as executor:
    # 启动两个线程
    result = executor.map(task, ('a', 'b', 'c', 'd'))
    
    for res in result:
        print(res)
```

当任务之间没有依赖关系，也没有通信，而且task单一，只是传入参数/处理对象不同时，更适合用map。 例如
- 下载图片的脚本，可迭代参数中存放每个图片的url，task函数只对传入的当前url进行下载
- 对于视频中的每一帧进行处理，可迭代参数中存放每帧的路径，task函数对传入的frame图片处理，处理后再写入处理后的图片文件

## 进程池
- 进程的创建和销毁比线程更加昂贵
- 频繁的创建和销毁线程对系统性能影响更大

```python
import time
from concurrent.futures import ProcessPoolExecutor


def task(name: str):
    print(f"{name} - step 1\n", end='')
    time.sleep(1)
    print(f"{name} - step 2\n", end='')
    return f"{name} finish"


if __name__ == '__main__':
    with ProcessPoolExecutor() as executor:
        # 启动两个线程
        result = executor.map(task, ('a', 'b', 'c', 'd'))

        for res in result:
            print(res)
```